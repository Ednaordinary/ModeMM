import io
import requests
import numpy as np
import base64
import json
from tqdm import tqdm

# Get a video generated by LTX Video from Modemm

print("Requesting T5 embeddings")

params = {"stream": False}
data = {"prompt": "meow", "pad": False}

# This returns a npy file as bytes with T5 prompt embeds for our prompt
T5_result = requests.get("http://127.0.0.1:14145/modemm/request/T5", params=params, json=data).json()

# Result is an error, print it
if "prompt_embeds" not in T5_result.keys():
    print(T5_result)
    exit(0)

# The model has returned the prompt embeds and an attention mask
prompt_embeds = T5_result["prompt_embeds"]["tensor"]
prompt_embeds = base64.b64decode(prompt_embeds.encode('UTF-8'))
prompt_embeds = io.BytesIO(prompt_embeds)

attn_mask = T5_result["attn_mask"]

# Load the npy file into a numpy array
prompt_embeds = np.load(prompt_embeds)

# You can now manipulate the prompt embeds however you want
...

# Turn them back into a file object and then bytes to send back to Modemm
prompt_file = io.BytesIO()
np.save(prompt_file, prompt_embeds)
prompt_file.seek(0)
prompt_embeds = prompt_file.read()


print("Requesting a transformer run")

# Pass the latents and prompt embeddings in order to run the model. The model passes out updated latents with the video encoded

params = {"stream": True}
data = {"prompt_embeds": base64.b64encode(prompt_embeds).decode('UTF-8'), "attn_mask": attn_mask, "height": 512, "width": 704}

if params["stream"]:
    # Optionally, stream progress from the Modemm server
    session = requests.Session()
    t = tqdm(total=224) # This is steps * transformer blocks * (2 if cfg is turned on)
    with session.get("http://127.0.0.1:14145/modemm/request/LTXVideo", params=params, json=data, stream=True) as response:
        for chunk in response.iter_content(chunk_size=None):
            if b"tensor" not in chunk:
                chunk = json.loads(chunk)
                t.update()
            #print(chunk)
            # The latents are the last line streamed
            if chunk != b'':
                latent = chunk
    t.close()
else:
    latent = requests.get("http://127.0.0.1:14145/modemm/request/LTXVideo", params=params, json=data).content

latent = json.loads(latent)

# Result is an error, print it
if "tensor" not in latent.keys():
    print(latent)
    exit(0)

print("Requesting VAE decode")

# Pass the latents to be decoded by the model

latent = latent["tensor"]

params = {"stream": False}
data = {"latents": latent}
latent = requests.get("http://127.0.0.1:14145/modemm/request/LTXVae", params=params, json=data).content

print(latent)